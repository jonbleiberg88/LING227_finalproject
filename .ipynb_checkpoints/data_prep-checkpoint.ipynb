{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nltk\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gensim.downloader as gdl\n",
    "\n",
    "# download pretrained 100D glove vectors\n",
    "pretrained_glove = gdl.load('glove-wiki-gigaword-100')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import brown\n",
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "# get average vector of all synsets of a given word\n",
    "def get_synset_vec(input_word, model, model_dim = 100, threshold = 3):\n",
    "    synsets = wn.synsets(input_word)\n",
    "    syn_words = set([s  for syn in synsets for s in syn.lemma_names()])\n",
    "    count = 0\n",
    "    syn_vec = np.zeros(model_dim)\n",
    "    for word in syn_words:\n",
    "        if word.lower() in model:\n",
    "            syn_vec += model.get_vector(word.lower())\n",
    "            count += 1\n",
    "    if count < threshold:\n",
    "        return False\n",
    "    return (syn_vec / count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract all trigrams that have a vector representation and are in wordnet\n",
    "def get_trigrams(words, model, doc_id):\n",
    "    wn_lemmas = set(wn.all_lemma_names())\n",
    "    trigrams = [None for _ in range(len(words) - 2)]\n",
    "    for i in range(len(words) - 2):\n",
    "        # loop through all trigrams in text\n",
    "        curr_trigram = (words[i], words[i+1], words[i+2], doc_id)\n",
    "        # include trigram if all words have a vector representation\n",
    "        if curr_trigram[0] in model and curr_trigram[1] in model and curr_trigram[2] in model:\n",
    "            if curr_trigram[1] in wn_lemmas:\n",
    "                trigrams[i] = curr_trigram\n",
    "    return [tri for tri in trigrams if tri is not None]\n",
    "\n",
    "# perturb the second word of each trigram\n",
    "def get_perturbations_by_synonym(trigrams, model, use_cos_sim = True):\n",
    "    perturbed_trigrams = [None for _ in range(len(trigrams))]\n",
    "    wn_lemmas = set(wn.all_lemma_names())\n",
    "    rand_idxs = np.random.randint(0,2,len(trigrams))\n",
    "    n_syns = 0\n",
    "    synset_vecs = {}\n",
    "    for idx, tri in enumerate(trigrams):\n",
    "        if idx % 1000 == 0:\n",
    "            print(idx)\n",
    "            print(n_syns)\n",
    "        # get 1st-3rd most similar word to middle word of trigram\n",
    "        if tri[1] in wn_lemmas:\n",
    "            if tri[1] in synset_vecs.keys():\n",
    "                perturbed_trigrams[idx] = synset_vecs[tri[1]]\n",
    "                n_syns += 1\n",
    "            else:\n",
    "                v = get_synset_vec(tri[1], model, model.vector_size)\n",
    "                if v is not False:\n",
    "                    perturbed_trigrams[idx] = v\n",
    "                    synset_vecs[tri[1]] = v\n",
    "                    n_syns += 1\n",
    "        elif use_cos_sim:\n",
    "            perturbed_trigrams[idx] = model.most_similar(tri[1], topn=3)[rand_idxs[idx]][0]\n",
    "    valid_tris = [t for t, p in zip(trigrams, perturbed_trigrams) if p is not None]\n",
    "    valid_perturbed = [p for p in perturbed_trigrams if p is not None]\n",
    "    return valid_tris, valid_perturbed\n",
    "\n",
    "# create trigram and perturbed word dataset\n",
    "def create_dataset(words, model, doc_id, use_cos_sim=True):\n",
    "    trigrams = get_trigrams(words, model, doc_id)\n",
    "    trigrams, perturbed_trigrams = get_perturbations_by_synonym(trigrams, model, use_cos_sim)\n",
    "    return trigrams, perturbed_trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "1000\n",
      "824\n",
      "2000\n",
      "1662\n",
      "3000\n",
      "2514\n",
      "4000\n",
      "3353\n",
      "5000\n",
      "4150\n",
      "6000\n",
      "4959\n",
      "7000\n",
      "5772\n",
      "8000\n",
      "6595\n",
      "9000\n",
      "7396\n",
      "10000\n",
      "8236\n",
      "11000\n",
      "9050\n",
      "12000\n",
      "9875\n",
      "13000\n",
      "10686\n",
      "14000\n",
      "11473\n",
      "15000\n",
      "12268\n",
      "16000\n",
      "13077\n",
      "17000\n",
      "13914\n",
      "18000\n",
      "14728\n",
      "19000\n",
      "15573\n",
      "20000\n",
      "16388\n",
      "21000\n",
      "17207\n",
      "22000\n",
      "18034\n",
      "23000\n",
      "18885\n",
      "24000\n",
      "19708\n"
     ]
    }
   ],
   "source": [
    "a,b = create_dataset(brown.words(categories='adventure'), pretrained_glove, 100, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
